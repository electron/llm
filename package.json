{
  "name": "@electron/llm",
  "version": "0.1.0",
  "description": "Load and use an LLM model directly in Electron",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "exports": {
    ".": {
      "types": "./dist/index.d.ts",
      "default": "./dist/index.js"
    },
    "./main": {
      "types": "./dist/main/index.d.ts",
      "default": "./dist/main/index.js"
    },
    "./renderer": {
      "types": "./dist/renderer/index.d.ts",
      "default": "./dist/renderer/index.js"
    },
    "./package.json": "./package.json"
  },
  "scripts": {
    "tsc": "tsc",
    "lint:check": "prettier --check \"**/*.{ts,js}\"",
    "lint:fix": "prettier --write \"**/*.{ts,js}\"",
    "test": "vitest run",
    "test:watch": "vitest",
    "test:coverage": "vitest run --coverage",
    "prepare": "husky install",
    "start": "electron-forge start",
    "package": "electron-forge package",
    "make": "electron-forge make"
  },
  "lint-staged": {
    "*.{js,ts}": [
      "prettier --write"
    ]
  },
  "type" : "module",
  "author": "Electron Community",
  "keywords": [
    "electron",
    "llm",
    "ai",
    "chat",
    "chatbot",
    "chatgpt",
    "llama",
    "llama.cpp"
  ],
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/electron/llm.git"
  },
  "dependencies": {
    "electron-squirrel-startup": "^1.0.1",
    "node-llama-cpp": "^3.5.0"
  },
  "devDependencies": {
    "@electron-forge/cli": "^7.7.0",
    "@electron-forge/maker-deb": "^7.7.0",
    "@electron-forge/maker-rpm": "^7.7.0",
    "@electron-forge/maker-squirrel": "^7.7.0",
    "@electron-forge/maker-zip": "^7.7.0",
    "@electron-forge/plugin-auto-unpack-natives": "^7.7.0",
    "@electron-forge/plugin-fuses": "^7.7.0",
    "@electron/fuses": "^1.8.0",
    "@tsconfig/node22": "^22.0.0",
    "@vitest/coverage-v8": "^3.0.7",
    "electron": "^34.3.0",
    "eslint": "^8.57.1",
    "husky": "^9.1.7",
    "lint-staged": "^15.4.3",
    "prettier": "^3.5.2",
    "typescript": "^5.7.3",
    "vitest": "^3.0.7"
  }
}
